{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec 19 17:08:19 2024\n",
    "\n",
    "@author: Rodrigo Meira\n",
    "\"\"\"\n",
    "from libs.eos_database import *\n",
    "from libs.compressor_class import *\n",
    "from libs.compression import *\n",
    "from libs.gc_eos_soave import *\n",
    "from libs.viscosity import *\n",
    "from libs.plenum_system import *\n",
    "from libs.simulation import *\n",
    "from libs.model import *\n",
    "\n",
    "from casadi import *\n",
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.stats import qmc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names = [\"CH4\", \"C2H6\", \"C3H8\", \"iC4H10\", \"nC4H10\", \"iC5H12\", \"nC5H12\", \n",
    "                  \"nC6H14\", \"nC7H16\", \"nC8H18\", \"nC9H20\", \"nC10H22\", \"nC11H24\", \n",
    "                   \"nC12H26\", \"nC14H30\", \"N2\", \"H2O\", \"CO2\", \"C15+\"]\n",
    "\n",
    "nwe = [0.9834, 0.0061, 0.0015, 0.0003, 0.0003, 0.00055, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0008, 0.0]\n",
    "\n",
    "dict_composition= {list_names[i]: nwe[i] for i in range(len(nwe))}\n",
    "\n",
    "mixture = Mixture(list_of_species, dict_composition)\n",
    "\n",
    "volumn_desviation = [0] * 19\n",
    "\n",
    "vlv = valve(kv=0.38)\n",
    "Vpp = 2.0 \n",
    "Lc = 2.0 \n",
    "A1 = 2.6e-3\n",
    "gas = gc_eos_class(mixture, 300, 4500, None, 1, 0, Aij, volumn_desviation, 'gas')\n",
    "comp = CompressorClass()\n",
    "visc = viscosity(mixture, volumn_desviation)\n",
    "compressor = compression(gas, comp, visc)\n",
    "plenum_sys = plenum(gas, compressor, vlv, Vpp, Lc, A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAlphas = 300\n",
    "\n",
    "sampler_N_RotS = qmc.LatinHypercube(d=1)  # d=1 porque estamos amostrando uma única variável\n",
    "samples_N_RotS = sampler_N_RotS.random(n=nAlphas+1)\n",
    "N_RotS = qmc.scale(samples_N_RotS, 600, 750).flatten()  # Redimensiona para 1D\n",
    "sampler_alphas = qmc.LatinHypercube(d=1)\n",
    "samples_alphas = sampler_alphas.random(n=nAlphas+1)\n",
    "alphas = qmc.scale(samples_alphas, 0.36, 0.65).flatten()\n",
    "\n",
    "nData = 40\n",
    "dt = 2\n",
    "timestep = 3\n",
    "x0 = [14.9919, 339.69, 0.42885]\n",
    "z0 = [6245.39, 6245.39, 321.672, 0.445562, 319.423, 0.503621, 320.097, 0.396345, 339.69, 0.42885, 0.514917]\n",
    "u0 = [4500, 300, 600, alphas[0], 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim = Simulation(plenum_sys, compressor, x0, z0, u0, nAlphas, alphas, N_RotS, nData, dt, timestep)\n",
    "# x_values, z_values, time_steps, alpha_values, N_values, x_train, y_train, x_min, x_max, y_min,y_max = sim.run()\n",
    "\n",
    "# sim_data = {\n",
    "#     \"x_values\": x_values,\n",
    "#     \"z_values\": z_values,\n",
    "#     \"time_steps\": time_steps,\n",
    "#     \"x_train\": x_train,\n",
    "#     \"y_train\": y_train,\n",
    "#     \"x_min\": x_min,\n",
    "#     \"x_max\": x_max,\n",
    "#     \"y_min\": y_min,\n",
    "#     \"y_max\": y_max\n",
    "\n",
    "# }\n",
    "\n",
    "# np.savez(\n",
    "#     \"simulation_data.npz\",\n",
    "#     x_values=x_values,\n",
    "#     z_values=z_values,\n",
    "#     time_steps=time_steps,\n",
    "#     alpha_values=alpha_values,\n",
    "#     N_values=N_values,\n",
    "#     x_train=x_train,\n",
    "#     y_train=y_train,\n",
    "#     x_min=x_min,\n",
    "#     x_max=x_max,\n",
    "#     y_min = y_min,\n",
    "#     y_max = y_max\n",
    "\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"simulation_data.npz\")\n",
    "\n",
    "x_values = data[\"x_values\"]\n",
    "z_values = data[\"z_values\"]\n",
    "time_steps = data[\"time_steps\"]\n",
    "alpha_values = data[\"alpha_values\"]\n",
    "N_values = data[\"N_values\"]\n",
    "x_train = data[\"x_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "x_min = data[\"x_min\"]\n",
    "x_max = data[\"x_max\"]\n",
    "y_min = data[\"y_min\"]\n",
    "y_max = data[\"y_max\"]\n",
    "\n",
    "\n",
    "x_min = torch.tensor(x_min, dtype = torch.float32)\n",
    "x_max = torch.tensor(x_max, dtype = torch.float32)\n",
    "y_min = torch.tensor(y_min, dtype = torch.float32)\n",
    "y_max = torch.tensor(y_max, dtype = torch.float32)\n",
    "x_train = torch.tensor(np.array(x_train), dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train), dtype=torch.float32)\n",
    "x_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    test_size=0.3,  \n",
    "    random_state=42,  \n",
    "    shuffle=True      \n",
    ")\n",
    "y_train_split = y_train_split.squeeze()\n",
    "y_val = y_val.squeeze()\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_split, y_train_split)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size= 64, shuffle=True)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size= 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(156, dt, x_max, x_min, y_min, y_max, plenum_sys)# Criar a instância do modelo novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_values = model.train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr= 1e-4,\n",
    "    epochs=4,\n",
    "    optimizers=torch.optim.Adam,\n",
    "    patience=100,\n",
    "    factor=0.5,\n",
    "    gas = gas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APAGAR DAQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " model, train_loader, val_loader, lr, epochs, optimizers, patience, factor, gas = model, train_loader, val_loader, 1e-4, 4, torch.optim.Adam, 100, 0.5, gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def _process_gas(args, gas_template):\n",
    "        y_pred_i, inputs_i, gas_template = args\n",
    "        gas = gas_template.copy_change_conditions(y_pred_i[1].item(), None, y_pred_i[2].item(), 'gas')\n",
    "        gas2 = gas_template.copy_change_conditions(y_pred_i[1].item(), y_pred_i[3].item(), None, 'gas')\n",
    "        gas.evaluate_der_eos_P()\n",
    "        return gas2.V.item(), gas.dPdV, gas.dPdT\n",
    "    \n",
    "def process_gas_batch(y_pred, inputs, gas_template, n_jobs=-1):\n",
    "        args_list = [(y_pred[i], inputs[i], gas_template) for i in range(y_pred.shape[0])]\n",
    "        \n",
    "        with Parallel(n_jobs=n_jobs) as parallel:\n",
    "            results = parallel(delayed(_process_gas)(args, gas_template) for args in args_list)\n",
    "        \n",
    "        Vp, dP_dV, dP_dT = zip(*results)\n",
    "        return torch.tensor(Vp, dtype=torch.float32), torch.tensor(dP_dV, dtype=torch.float32), torch.tensor(dP_dT, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_residuals(z, x0, u0, plenum_sys):\n",
    "        \"\"\"Calcula apenas os resíduos algébricos, mantendo x0 fixo\"\"\"\n",
    "        print(z, x0, u0)\n",
    "        _, alg_sym = plenum_sys.evaluate_dae(None, x0, z, u0)\n",
    "        return np.array([alg_sym[i] for i in range(11)])  # Retorna apenas as equações algébricas\n",
    "\n",
    "def compute_steady_state(u0, plenum_sys, x0, z0):\n",
    "        \"\"\"Calcula apenas o estado estacionário das variáveis algébricas\"\"\"\n",
    "        sol = fsolve(system_residuals, z0, args=(x0, u0, plenum_sys))\n",
    "        return x0, sol  # Retorna x0 (fixo) e z calculado\n",
    "    \n",
    "@staticmethod\n",
    "def _process_steady_state(args, plenum_sys):\n",
    "        u0, x0, z0 = args\n",
    "        return compute_steady_state(u0, plenum_sys, x0, z0)\n",
    "    \n",
    "def compute_steady_state_batch(u0_batch, plenum_sys, x0_batch, z0_batch, n_jobs=-1):\n",
    "        process_fn = partial(_process_steady_state, plenum_sys=plenum_sys)\n",
    "        args_list = list(zip(u0_batch, x0_batch, z0_batch))\n",
    "        \n",
    "        with Parallel(n_jobs=n_jobs) as parallel:\n",
    "            results = parallel(delayed(process_fn)(args) for args in args_list)\n",
    "        \n",
    "        x_ss_batch, z_ss_batch = zip(*results)\n",
    "        return np.stack(x_ss_batch), np.stack(z_ss_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "        optimizer = optimizers(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=factor, patience=patience\n",
    "        )\n",
    "\n",
    "        model.train()\n",
    "        train_loss_values = []\n",
    "        val_loss_values = []\n",
    "        physics_loss_values = []\n",
    "        coeff = torch.tensor([11, -18, 9, -2], dtype=torch.float32) / (6 * dt)\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            total_loss_physics = 0\n",
    "            \n",
    "            for batch_idx, (inputs, y_true) in enumerate(train_loader):\n",
    "                start_time = time.time()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward Pass\n",
    "                y_pred = model(inputs)\n",
    "                \n",
    "                # Loss de dados\n",
    "                loss_data = (\n",
    "                    1e2 * torch.mean((y_true[:, 0] - y_pred[:, 0]) ** 2) +\n",
    "                    1e1 * torch.mean((y_true[:, 1] - y_pred[:, 1]) ** 2) +\n",
    "                    1e-6 * torch.mean((y_true[:, 3] - y_pred[:, 3]) ** 2) +\n",
    "                    1e-6 * torch.mean((y_true[:, 4] - y_pred[:, 4]) ** 2) +\n",
    "                    1e-4 * torch.mean((y_true[:, 11] - y_pred[:, 11]) ** 2)\n",
    "                )\n",
    "                \n",
    "                # Cálculo das derivadas temporais (vetorizado)\n",
    "                m_t = torch.sum(coeff.view(1, -1) * torch.cat([\n",
    "                    y_true[:, 0:1], \n",
    "                    inputs[:, -3:, 0]\n",
    "                ], dim=1), dim=1)\n",
    "                \n",
    "                t_t = torch.sum(coeff.view(1, -1) * torch.cat([\n",
    "                    y_true[:, 1:2], \n",
    "                    inputs[:, -3:, 1]\n",
    "                ], dim=1), dim=1)\n",
    "                \n",
    "                P_t = torch.sum(coeff.view(1, -1) * torch.cat([\n",
    "                    y_true[:, 3:4], \n",
    "                    inputs[:, -3:, 2]\n",
    "                ], dim=1), dim=1)\n",
    "                \n",
    "                # Processamento paralelo das propriedades do gás\n",
    "                Vp, dP_dV, dP_dT = process_gas_batch(y_pred, inputs, gas)\n",
    "                \n",
    "                # Cálculo do estado estacionário em paralelo (apenas para z)\n",
    "                with torch.no_grad():\n",
    "                    u0_batch = np.stack([\n",
    "                        np.array([4500, 300, inputs[i, -1, -1].item(), \n",
    "                                inputs[i, -1, -2].item(), 5000])\n",
    "                        for i in range(inputs.shape[0])\n",
    "                    ])\n",
    "                    x0_batch = y_pred[:, :3].detach().numpy()\n",
    "                    z0_batch = y_true[:, 3:].detach().numpy()\n",
    "                    break\n",
    "                    # x_ss, z_ss = compute_steady_state_batch(u0_batch, plenum, x0_batch, z0_batch, n_jobs = -1)\n",
    "                    # z_ss = torch.tensor(z_ss, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0_batch, plenum_sys, x0_batch, z0_batch, n_jobs = u0_batch, plenum, x0_batch, z0_batch,  -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        process_fn = partial(_process_steady_state, plenum_sys=plenum_sys)\n",
    "        args_list = list(zip(u0_batch, x0_batch, z0_batch))\n",
    "        \n",
    "        with Parallel(n_jobs=n_jobs) as parallel:\n",
    "            results = parallel(delayed(process_fn)(args) for args in args_list)\n",
    "        \n",
    "        x_ss_batch, z_ss_batch = zip(*results)\n",
    "        # return np.stack(x_ss_batch), np.stack(z_ss_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<staticmethod(<function _process_steady_state at 0x71fbf6dc69e0>)>, plenum_sys=<class 'libs.plenum_system.plenum'>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial(_process_steady_state, plenum_sys=plenum_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4500, 300, 600, 0.624488779189459, 5000]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_steady_state(u0, plenum_sys, x0, z0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ATE AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAlphas_teste = 7\n",
    "\n",
    "sampler_N_RotS_teste = qmc.LatinHypercube(d=1)  # d=1 porque estamos amostrando uma única variável\n",
    "samples_N_RotS_teste = sampler_N_RotS_teste.random(n=nAlphas_teste+1)\n",
    "N_RotS_teste = qmc.scale(samples_N_RotS_teste, 600, 750).flatten()  # Redimensiona para 1D\n",
    "sampler_alphas_teste = qmc.LatinHypercube(d=1)\n",
    "samples_alphas_teste = sampler_alphas_teste.random(n=nAlphas_teste+1)\n",
    "alphas_teste = qmc.scale(samples_alphas_teste, 0.35, 0.65).flatten()\n",
    "\n",
    "sim2 = sim = Simulation(plenum_sys, compressor, x0, z0, u0, nAlphas_teste, alphas_teste, N_RotS_teste, 40, dt, timestep)\n",
    "x_values_teste, z_values_teste, time_steps, alpha_values_teste, N_values_teste, x_teste, y_teste, x_min, x_max, y_min, y_max = sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Rodar a inferência corretamente\n",
    "model.eval()  # Importante colocar a rede em modo de avaliação\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_teste)\n",
    "\n",
    "# Checar se y_pred realmente varia\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: mean={param.mean().item()}, std={param.std().item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Remover dimensões extras de y_pred e y_teste (se houver)\n",
    "y_pred = y_pred.squeeze()\n",
    "y_teste = y_teste.squeeze()\n",
    "\n",
    "# Número de variáveis de saída\n",
    "num_outputs = y_teste.shape[1]\n",
    "\n",
    "# Ajustar o tamanho da lista time_steps para corresponder aos dados de teste\n",
    "time_steps = time_steps[:y_teste.shape[0]]\n",
    " \n",
    "# Criar os gráficos separadamente para cada saída\n",
    "for i in range(num_outputs):\n",
    "    plt.figure(figsize=(8, 4))  # Criar uma nova figura para cada gráfico\n",
    "    plt.plot(time_steps, y_teste[:, i], label=\"Saída Esperada (y_teste)\", color=\"red\", linestyle=\"--\")\n",
    "    plt.plot(time_steps, y_pred[:, i], label=\"Saída da Rede (y_pred)\", color=\"blue\", linestyle=\"-\")\n",
    "    \n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.title(f\"Saída {i}\")  # Título do gráfico indicando o índice da saída\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()  # Mostrar o gráfico\n",
    "\n",
    "\"[0, 1, 2, 3, 5, 7, 9, 11]\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
