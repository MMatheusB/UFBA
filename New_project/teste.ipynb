{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec 19 17:08:19 2024\n",
    "\n",
    "@author: Rodrigo Meira\n",
    "\"\"\"\n",
    "from libs.eos_database import *\n",
    "from libs.compressor_class import *\n",
    "from libs.compression import *\n",
    "from libs.gc_eos_soave import *\n",
    "from libs.viscosity import *\n",
    "from libs.plenum_system import *\n",
    "from libs.simulation import *\n",
    "from libs.model import *\n",
    "\n",
    "from casadi import *\n",
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.stats import qmc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names = [\"CH4\", \"C2H6\", \"C3H8\", \"iC4H10\", \"nC4H10\", \"iC5H12\", \"nC5H12\", \n",
    "                  \"nC6H14\", \"nC7H16\", \"nC8H18\", \"nC9H20\", \"nC10H22\", \"nC11H24\", \n",
    "                   \"nC12H26\", \"nC14H30\", \"N2\", \"H2O\", \"CO2\", \"C15+\"]\n",
    "\n",
    "nwe = [0.9834, 0.0061, 0.0015, 0.0003, 0.0003, 0.00055, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0008, 0.0]\n",
    "\n",
    "dict_composition= {list_names[i]: nwe[i] for i in range(len(nwe))}\n",
    "\n",
    "mixture = Mixture(list_of_species, dict_composition)\n",
    "\n",
    "volumn_desviation = [0] * 19\n",
    "\n",
    "vlv = valve(kv=0.38)\n",
    "Vpp = 2.0 \n",
    "Lc = 2.0 \n",
    "A1 = 2.6e-3\n",
    "gas = gc_eos_class(mixture, 300, 4500, None, 1, 0, Aij, volumn_desviation, 'gas')\n",
    "comp = CompressorClass()\n",
    "visc = viscosity(mixture, volumn_desviation)\n",
    "compressor = compression(gas, comp, visc)\n",
    "plenum_sys = plenum(gas, compressor, vlv, Vpp, Lc, A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAlphas = 300\n",
    "\n",
    "sampler_N_RotS = qmc.LatinHypercube(d=1)  # d=1 porque estamos amostrando uma única variável\n",
    "samples_N_RotS = sampler_N_RotS.random(n=nAlphas+1)\n",
    "N_RotS = qmc.scale(samples_N_RotS, 600, 750).flatten()  # Redimensiona para 1D\n",
    "sampler_alphas = qmc.LatinHypercube(d=1)\n",
    "samples_alphas = sampler_alphas.random(n=nAlphas+1)\n",
    "alphas = qmc.scale(samples_alphas, 0.36, 0.65).flatten()\n",
    "\n",
    "nData = 40\n",
    "dt = 2\n",
    "timestep = 3\n",
    "x0 = [14.9919, 339.69, 0.42885]\n",
    "z0 = [6245.39, 6245.39, 321.672, 0.445562, 319.423, 0.503621, 320.097, 0.396345, 339.69, 0.42885, 0.514917]\n",
    "u0 = [4500, 300, 600, alphas[0], 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim = Simulation(plenum_sys, compressor, x0, z0, u0, nAlphas, alphas, N_RotS, nData, dt, timestep)\n",
    "# x_values, z_values, time_steps, alpha_values, N_values, x_train, y_train, x_min, x_max, y_min,y_max = sim.run()\n",
    "\n",
    "# sim_data = {\n",
    "#     \"x_values\": x_values,\n",
    "#     \"z_values\": z_values,\n",
    "#     \"time_steps\": time_steps,\n",
    "#     \"x_train\": x_train,\n",
    "#     \"y_train\": y_train,\n",
    "#     \"x_min\": x_min,\n",
    "#     \"x_max\": x_max,\n",
    "#     \"y_min\": y_min,\n",
    "#     \"y_max\": y_max\n",
    "\n",
    "# }\n",
    "\n",
    "# np.savez(\n",
    "#     \"simulation_data.npz\",\n",
    "#     x_values=x_values,\n",
    "#     z_values=z_values,\n",
    "#     time_steps=time_steps,\n",
    "#     alpha_values=alpha_values,\n",
    "#     N_values=N_values,\n",
    "#     x_train=x_train,\n",
    "#     y_train=y_train,\n",
    "#     x_min=x_min,\n",
    "#     x_max=x_max,\n",
    "#     y_min = y_min,\n",
    "#     y_max = y_max\n",
    "\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"simulation_data.npz\")\n",
    "\n",
    "x_values = data[\"x_values\"]\n",
    "z_values = data[\"z_values\"]\n",
    "time_steps = data[\"time_steps\"]\n",
    "alpha_values = data[\"alpha_values\"]\n",
    "N_values = data[\"N_values\"]\n",
    "x_train = data[\"x_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "x_min = data[\"x_min\"]\n",
    "x_max = data[\"x_max\"]\n",
    "y_min = data[\"y_min\"]\n",
    "y_max = data[\"y_max\"]\n",
    "\n",
    "\n",
    "x_min = torch.tensor(x_min, dtype = torch.float32)\n",
    "x_max = torch.tensor(x_max, dtype = torch.float32)\n",
    "y_min = torch.tensor(y_min, dtype = torch.float32)\n",
    "y_max = torch.tensor(y_max, dtype = torch.float32)\n",
    "x_train = torch.tensor(np.array(x_train), dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train), dtype=torch.float32)\n",
    "x_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    test_size=0.3,  \n",
    "    random_state=42,  \n",
    "    shuffle=True      \n",
    ")\n",
    "y_train_split = y_train_split.squeeze()\n",
    "y_val = y_val.squeeze()\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_split, y_train_split)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size= 64, shuffle=True)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size= 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(156, dt, x_max, x_min, y_min, y_max, plenum_sys)# Criar a instância do modelo novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 completed in 9.65s\n",
      "Batch 1 completed in 5.64s\n",
      "Batch 2 completed in 6.65s\n",
      "Batch 3 completed in 5.55s\n",
      "Batch 4 completed in 5.40s\n",
      "Batch 5 completed in 6.13s\n",
      "Batch 6 completed in 5.32s\n",
      "Batch 7 completed in 4.78s\n",
      "Batch 8 completed in 5.53s\n",
      "Batch 9 completed in 5.41s\n",
      "Batch 10 completed in 5.68s\n",
      "Batch 11 completed in 5.67s\n",
      "Batch 12 completed in 6.17s\n",
      "Batch 13 completed in 6.06s\n",
      "Batch 14 completed in 4.68s\n",
      "Batch 15 completed in 5.35s\n",
      "Batch 16 completed in 5.99s\n",
      "Batch 17 completed in 5.86s\n",
      "Batch 18 completed in 5.41s\n",
      "Batch 19 completed in 5.87s\n",
      "Batch 20 completed in 6.22s\n",
      "Batch 21 completed in 5.31s\n",
      "Batch 22 completed in 6.13s\n",
      "Batch 23 completed in 5.68s\n",
      "Batch 24 completed in 5.29s\n",
      "Batch 25 completed in 5.93s\n",
      "Batch 26 completed in 5.44s\n",
      "Batch 27 completed in 5.28s\n",
      "Batch 28 completed in 6.44s\n",
      "Batch 29 completed in 5.23s\n",
      "Batch 30 completed in 5.33s\n",
      "Batch 31 completed in 5.58s\n",
      "Batch 32 completed in 5.00s\n",
      "Batch 33 completed in 6.06s\n",
      "Batch 34 completed in 5.47s\n",
      "Batch 35 completed in 4.50s\n",
      "Batch 36 completed in 6.47s\n",
      "Batch 37 completed in 4.86s\n",
      "Batch 38 completed in 5.01s\n",
      "Batch 39 completed in 5.10s\n",
      "Batch 40 completed in 4.86s\n",
      "Batch 41 completed in 5.07s\n",
      "Batch 42 completed in 5.08s\n",
      "Batch 43 completed in 4.93s\n",
      "Batch 44 completed in 6.04s\n",
      "Batch 45 completed in 5.45s\n",
      "Batch 46 completed in 4.88s\n",
      "Batch 47 completed in 6.26s\n",
      "Batch 48 completed in 4.77s\n",
      "Batch 49 completed in 5.56s\n",
      "Batch 50 completed in 6.20s\n",
      "Batch 51 completed in 5.41s\n",
      "Batch 52 completed in 5.14s\n",
      "Batch 53 completed in 4.96s\n",
      "Batch 54 completed in 4.28s\n",
      "Batch 55 completed in 6.32s\n",
      "Batch 56 completed in 5.44s\n",
      "Batch 57 completed in 5.27s\n",
      "Batch 58 completed in 4.85s\n",
      "Batch 59 completed in 5.90s\n",
      "Batch 60 completed in 4.37s\n",
      "Batch 61 completed in 6.31s\n",
      "Batch 62 completed in 5.88s\n",
      "Batch 63 completed in 5.04s\n",
      "Batch 64 completed in 6.59s\n",
      "Batch 65 completed in 5.76s\n",
      "Batch 66 completed in 5.12s\n",
      "Batch 67 completed in 5.19s\n",
      "Batch 68 completed in 5.29s\n",
      "Batch 69 completed in 4.69s\n",
      "Batch 70 completed in 5.38s\n",
      "Batch 71 completed in 5.68s\n",
      "Batch 72 completed in 5.44s\n",
      "Batch 73 completed in 5.32s\n",
      "Batch 74 completed in 5.58s\n",
      "Batch 75 completed in 4.84s\n",
      "Batch 76 completed in 6.47s\n",
      "Batch 77 completed in 5.62s\n",
      "Batch 78 completed in 4.82s\n",
      "Batch 79 completed in 4.89s\n",
      "Batch 80 completed in 5.11s\n",
      "Batch 81 completed in 4.76s\n",
      "Batch 82 completed in 5.37s\n",
      "Batch 83 completed in 5.15s\n",
      "Batch 84 completed in 5.19s\n",
      "Batch 85 completed in 5.16s\n",
      "Batch 86 completed in 6.22s\n",
      "Batch 87 completed in 4.59s\n",
      "Batch 88 completed in 6.19s\n",
      "Batch 89 completed in 6.57s\n",
      "Batch 90 completed in 4.94s\n",
      "Batch 91 completed in 5.69s\n",
      "Batch 92 completed in 5.66s\n",
      "Batch 93 completed in 5.85s\n",
      "Batch 94 completed in 5.28s\n",
      "Batch 95 completed in 5.29s\n",
      "Batch 96 completed in 5.74s\n",
      "Batch 97 completed in 5.10s\n",
      "Batch 98 completed in 6.04s\n",
      "Batch 99 completed in 5.20s\n",
      "Batch 100 completed in 6.11s\n",
      "Batch 101 completed in 5.11s\n",
      "Batch 102 completed in 4.52s\n",
      "Batch 103 completed in 5.25s\n",
      "Batch 104 completed in 4.62s\n",
      "Batch 105 completed in 5.71s\n",
      "Batch 106 completed in 5.20s\n",
      "Batch 107 completed in 4.99s\n",
      "Batch 108 completed in 4.89s\n",
      "Batch 109 completed in 5.96s\n",
      "Batch 110 completed in 5.40s\n",
      "Batch 111 completed in 5.17s\n",
      "Batch 112 completed in 5.13s\n",
      "Batch 113 completed in 4.58s\n",
      "Batch 114 completed in 5.79s\n",
      "Batch 115 completed in 4.59s\n",
      "Batch 116 completed in 5.85s\n",
      "Batch 117 completed in 4.54s\n",
      "Batch 118 completed in 5.03s\n",
      "Batch 119 completed in 4.86s\n",
      "Batch 120 completed in 4.71s\n",
      "Batch 121 completed in 4.85s\n",
      "Batch 122 completed in 4.43s\n",
      "Batch 123 completed in 5.47s\n",
      "Batch 124 completed in 4.92s\n",
      "Batch 125 completed in 5.10s\n",
      "Batch 126 completed in 4.10s\n",
      "Batch 127 completed in 5.07s\n",
      "Batch 128 completed in 4.64s\n",
      "Batch 129 completed in 4.56s\n",
      "Batch 130 completed in 4.96s\n",
      "Batch 131 completed in 1.48s\n",
      "Epoch [1/30], Train Loss: 512.750284, Val Loss: 39265.516482, Learning Rate: 0.000100, Physics Loss: 5924.786088\n",
      "Batch 0 completed in 5.74s\n",
      "Batch 1 completed in 4.68s\n",
      "Batch 2 completed in 4.82s\n",
      "Batch 3 completed in 4.78s\n",
      "Batch 4 completed in 4.75s\n",
      "Batch 5 completed in 5.20s\n",
      "Batch 6 completed in 6.07s\n",
      "Batch 7 completed in 4.59s\n",
      "Batch 8 completed in 6.24s\n",
      "Batch 9 completed in 5.28s\n",
      "Batch 10 completed in 4.61s\n",
      "Batch 11 completed in 5.69s\n",
      "Batch 12 completed in 4.49s\n",
      "Batch 13 completed in 4.87s\n",
      "Batch 14 completed in 6.04s\n",
      "Batch 15 completed in 4.89s\n",
      "Batch 16 completed in 5.46s\n",
      "Batch 17 completed in 5.66s\n",
      "Batch 18 completed in 4.62s\n",
      "Batch 19 completed in 5.38s\n",
      "Batch 20 completed in 4.57s\n",
      "Batch 21 completed in 5.47s\n",
      "Batch 22 completed in 5.97s\n",
      "Batch 23 completed in 4.77s\n",
      "Batch 24 completed in 6.36s\n",
      "Batch 25 completed in 5.65s\n",
      "Batch 26 completed in 4.76s\n",
      "Batch 27 completed in 5.78s\n",
      "Batch 28 completed in 4.83s\n",
      "Batch 29 completed in 6.37s\n",
      "Batch 30 completed in 5.71s\n",
      "Batch 31 completed in 4.83s\n"
     ]
    }
   ],
   "source": [
    "train_loss_values = model.train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr= 1e-4,\n",
    "    epochs=30,\n",
    "    optimizers=torch.optim.Adam,\n",
    "    patience=100,\n",
    "    factor=0.5,\n",
    "    gas = gas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAlphas_teste = 7\n",
    "\n",
    "sampler_N_RotS_teste = qmc.LatinHypercube(d=1)  # d=1 porque estamos amostrando uma única variável\n",
    "samples_N_RotS_teste = sampler_N_RotS_teste.random(n=nAlphas_teste+1)\n",
    "N_RotS_teste = qmc.scale(samples_N_RotS_teste, 600, 750).flatten()  # Redimensiona para 1D\n",
    "sampler_alphas_teste = qmc.LatinHypercube(d=1)\n",
    "samples_alphas_teste = sampler_alphas_teste.random(n=nAlphas_teste+1)\n",
    "alphas_teste = qmc.scale(samples_alphas_teste, 0.35, 0.65).flatten()\n",
    "\n",
    "sim2 = sim = Simulation(plenum_sys, compressor, x0, z0, u0, nAlphas_teste, alphas_teste, N_RotS_teste, 40, dt, timestep)\n",
    "x_values_teste, z_values_teste, time_steps, alpha_values_teste, N_values_teste, x_teste, y_teste, x_min, x_max, y_min, y_max = sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Rodar a inferência corretamente\n",
    "model.eval()  # Importante colocar a rede em modo de avaliação\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_teste)\n",
    "\n",
    "# Checar se y_pred realmente varia\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: mean={param.mean().item()}, std={param.std().item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Remover dimensões extras de y_pred e y_teste (se houver)\n",
    "y_pred = y_pred.squeeze()\n",
    "y_teste = y_teste.squeeze()\n",
    "\n",
    "# Número de variáveis de saída\n",
    "num_outputs = y_teste.shape[1]\n",
    "\n",
    "# Ajustar o tamanho da lista time_steps para corresponder aos dados de teste\n",
    "time_steps = time_steps[:y_teste.shape[0]]\n",
    " \n",
    "# Criar os gráficos separadamente para cada saída\n",
    "for i in range(num_outputs):\n",
    "    plt.figure(figsize=(8, 4))  # Criar uma nova figura para cada gráfico\n",
    "    plt.plot(time_steps, y_teste[:, i], label=\"Saída Esperada (y_teste)\", color=\"red\", linestyle=\"--\")\n",
    "    plt.plot(time_steps, y_pred[:, i], label=\"Saída da Rede (y_pred)\", color=\"blue\", linestyle=\"-\")\n",
    "    \n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.title(f\"Saída {i}\")  # Título do gráfico indicando o índice da saída\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()  # Mostrar o gráfico\n",
    "\n",
    "\"[0, 1, 2, 3, 5, 7, 9, 11]\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
