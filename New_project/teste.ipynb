{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec 19 17:08:19 2024\n",
    "\n",
    "@author: Rodrigo Meira\n",
    "\"\"\"\n",
    "from libs.eos_database import *\n",
    "from libs.compressor_class import *\n",
    "from libs.compression import *\n",
    "from libs.gc_eos_soave import *\n",
    "from libs.viscosity import *\n",
    "from libs.plenum_system import *\n",
    "from libs.simulation import *\n",
    "from libs.model import *\n",
    "\n",
    "from casadi import *\n",
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.stats import qmc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names = [\"CH4\", \"C2H6\", \"C3H8\", \"iC4H10\", \"nC4H10\", \"iC5H12\", \"nC5H12\", \n",
    "                  \"nC6H14\", \"nC7H16\", \"nC8H18\", \"nC9H20\", \"nC10H22\", \"nC11H24\", \n",
    "                   \"nC12H26\", \"nC14H30\", \"N2\", \"H2O\", \"CO2\", \"C15+\"]\n",
    "\n",
    "nwe = [0.9834, 0.0061, 0.0015, 0.0003, 0.0003, 0.00055, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003, 0.0, 0.0008, 0.0]\n",
    "\n",
    "dict_composition= {list_names[i]: nwe[i] for i in range(len(nwe))}\n",
    "\n",
    "mixture = Mixture(list_of_species, dict_composition)\n",
    "\n",
    "volumn_desviation = [0] * 19\n",
    "\n",
    "vlv = valve(kv=0.38)\n",
    "Vpp = 2.0 \n",
    "Lc = 2.0 \n",
    "A1 = 2.6e-3\n",
    "gas = gc_eos_class(mixture, 300, 4500, None, 1, 0, Aij, volumn_desviation, 'gas')\n",
    "comp = CompressorClass()\n",
    "visc = viscosity(mixture, volumn_desviation)\n",
    "compressor = compression(gas, comp, visc)\n",
    "plenum_sys = plenum(gas, compressor, vlv, Vpp, Lc, A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAlphas = 300\n",
    "\n",
    "sampler_N_RotS = qmc.LatinHypercube(d=1)  # d=1 porque estamos amostrando uma única variável\n",
    "samples_N_RotS = sampler_N_RotS.random(n=nAlphas+1)\n",
    "N_RotS = qmc.scale(samples_N_RotS, 600, 750).flatten()  # Redimensiona para 1D\n",
    "sampler_alphas = qmc.LatinHypercube(d=1)\n",
    "samples_alphas = sampler_alphas.random(n=nAlphas+1)\n",
    "alphas = qmc.scale(samples_alphas, 0.36, 0.65).flatten()\n",
    "\n",
    "nData = 40\n",
    "dt = 2\n",
    "timestep = 3\n",
    "x0 = [14.9919, 339.69, 0.42885]\n",
    "z0 = [6245.39, 6245.39, 321.672, 0.445562, 319.423, 0.503621, 320.097, 0.396345, 339.69, 0.42885, 0.514917]\n",
    "u0 = [4500, 300, 600, alphas[0], 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim = Simulation(plenum_sys, compressor, x0, z0, u0, nAlphas, alphas, N_RotS, nData, dt, timestep)\n",
    "# x_values, z_values, time_steps, alpha_values, N_values, x_train, y_train, x_min, x_max, y_min,y_max = sim.run()\n",
    "\n",
    "# sim_data = {\n",
    "#     \"x_values\": x_values,\n",
    "#     \"z_values\": z_values,\n",
    "#     \"time_steps\": time_steps,\n",
    "#     \"x_train\": x_train,\n",
    "#     \"y_train\": y_train,\n",
    "#     \"x_min\": x_min,\n",
    "#     \"x_max\": x_max,\n",
    "#     \"y_min\": y_min,\n",
    "#     \"y_max\": y_max\n",
    "\n",
    "# }\n",
    "\n",
    "# np.savez(\n",
    "#     \"simulation_data.npz\",\n",
    "#     x_values=x_values,\n",
    "#     z_values=z_values,\n",
    "#     time_steps=time_steps,\n",
    "#     alpha_values=alpha_values,\n",
    "#     N_values=N_values,\n",
    "#     x_train=x_train,\n",
    "#     y_train=y_train,\n",
    "#     x_min=x_min,\n",
    "#     x_max=x_max,\n",
    "#     y_min = y_min,\n",
    "#     y_max = y_max\n",
    "\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"simulation_data.npz\")\n",
    "\n",
    "x_values = data[\"x_values\"]\n",
    "z_values = data[\"z_values\"]\n",
    "time_steps = data[\"time_steps\"]\n",
    "alpha_values = data[\"alpha_values\"]\n",
    "N_values = data[\"N_values\"]\n",
    "x_train = data[\"x_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "x_min = data[\"x_min\"]\n",
    "x_max = data[\"x_max\"]\n",
    "y_min = data[\"y_min\"]\n",
    "y_max = data[\"y_max\"]\n",
    "\n",
    "\n",
    "x_min = torch.tensor(x_min, dtype = torch.float32)\n",
    "x_max = torch.tensor(x_max, dtype = torch.float32)\n",
    "y_min = torch.tensor(y_min, dtype = torch.float32)\n",
    "y_max = torch.tensor(y_max, dtype = torch.float32)\n",
    "x_train = torch.tensor(np.array(x_train), dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train), dtype=torch.float32)\n",
    "x_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    test_size=0.3,  \n",
    "    random_state=42,  \n",
    "    shuffle=True      \n",
    ")\n",
    "y_train_split = y_train_split.squeeze()\n",
    "y_val = y_val.squeeze()\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_split, y_train_split)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size= 64, shuffle=True)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size= 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(128, dt, x_max, x_min, y_min, y_max, plenum_sys)# Criar a instância do modelo novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo = MyModel(200, dt, x_max, x_min, y_min, y_max, plenum_sys)  # mesma definição usada antes\n",
    "# modelo.load_state_dict(torch.load('pesos_modelo.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 completed in 6.79s | Data: 13578.3613 | Phys: 18.2246 | Prof: 427.6821\n",
      "Batch 1 completed in 3.48s | Data: 17890.0586 | Phys: 16.3881 | Prof: 448.2281\n",
      "Batch 2 completed in 3.49s | Data: 16555.8359 | Phys: 17.3265 | Prof: 331.9055\n",
      "Batch 3 completed in 3.61s | Data: 11879.9453 | Phys: 17.7669 | Prof: 211.9219\n",
      "Batch 4 completed in 3.47s | Data: 17112.6562 | Phys: 18.7026 | Prof: 222.3085\n",
      "Batch 5 completed in 3.48s | Data: 11224.7832 | Phys: 15.2649 | Prof: 122.0032\n",
      "Batch 6 completed in 3.60s | Data: 14973.6680 | Phys: 15.1641 | Prof: 97.7177\n",
      "Batch 7 completed in 0.53s | Data: 11807.1777 | Phys: 15.2735 | Prof: 91.3122\n",
      "Batch 8 completed in 3.49s | Data: 11113.0713 | Phys: 14.2181 | Prof: 56.4868\n",
      "Batch 9 completed in 3.50s | Data: 12984.5742 | Phys: 13.6822 | Prof: 51.6035\n",
      "Batch 10 completed in 3.57s | Data: 8299.0059 | Phys: 12.9153 | Prof: 75.6053\n",
      "Batch 11 completed in 3.49s | Data: 8069.6328 | Phys: 11.7932 | Prof: 49.3627\n",
      "Batch 12 completed in 3.51s | Data: 9116.6426 | Phys: 12.1552 | Prof: 87.7735\n",
      "Batch 13 completed in 3.51s | Data: 9421.0693 | Phys: 12.6807 | Prof: 87.4431\n",
      "Batch 14 completed in 3.45s | Data: 6648.7617 | Phys: 10.0878 | Prof: 100.7565\n",
      "Batch 15 completed in 3.47s | Data: 7222.0986 | Phys: 11.7414 | Prof: 100.2286\n",
      "Batch 16 completed in 0.51s | Data: 8524.6289 | Phys: 13.6193 | Prof: 119.0651\n",
      "Batch 17 completed in 3.52s | Data: 6147.6743 | Phys: 12.6406 | Prof: 128.0426\n",
      "Batch 18 completed in 3.49s | Data: 5049.3496 | Phys: 11.3150 | Prof: 122.0247\n",
      "Batch 19 completed in 3.45s | Data: 4831.7461 | Phys: 9.9714 | Prof: 105.0548\n",
      "Batch 20 completed in 3.46s | Data: 4799.3071 | Phys: 9.4340 | Prof: 97.2879\n",
      "Batch 21 completed in 3.47s | Data: 3969.1055 | Phys: 9.2693 | Prof: 89.0447\n",
      "Batch 22 completed in 3.48s | Data: 4280.8628 | Phys: 9.6524 | Prof: 78.9272\n",
      "Batch 23 completed in 3.45s | Data: 4973.6235 | Phys: 10.6219 | Prof: 85.9771\n",
      "Batch 24 completed in 3.45s | Data: 3507.2930 | Phys: 8.3837 | Prof: 71.0637\n",
      "Batch 25 completed in 0.53s | Data: 2851.0884 | Phys: 8.4746 | Prof: 57.6366\n",
      "Batch 26 completed in 3.45s | Data: 3348.1399 | Phys: 9.5836 | Prof: 39.2489\n",
      "Batch 27 completed in 3.47s | Data: 2542.4302 | Phys: 6.8093 | Prof: 25.4352\n",
      "Batch 28 completed in 3.55s | Data: 2626.1519 | Phys: 9.1396 | Prof: 20.4045\n",
      "Batch 29 completed in 3.42s | Data: 2345.5659 | Phys: 8.2445 | Prof: 23.6340\n",
      "Batch 30 completed in 3.47s | Data: 2149.8181 | Phys: 8.2012 | Prof: 24.8289\n",
      "Batch 31 completed in 3.48s | Data: 1460.6489 | Phys: 6.0664 | Prof: 21.2509\n",
      "Batch 32 completed in 3.47s | Data: 2679.6069 | Phys: 8.7500 | Prof: 42.7718\n",
      "Batch 33 completed in 3.48s | Data: 1316.5391 | Phys: 5.8610 | Prof: 19.0276\n",
      "Batch 34 completed in 3.42s | Data: 1399.6653 | Phys: 6.9476 | Prof: 25.2016\n",
      "Batch 35 completed in 0.47s | Data: 1297.5391 | Phys: 5.8068 | Prof: 15.2382\n",
      "Batch 36 completed in 3.43s | Data: 1155.1256 | Phys: 5.7157 | Prof: 21.5741\n",
      "Batch 37 completed in 3.61s | Data: 1367.0437 | Phys: 6.0198 | Prof: 29.9140\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_loss_values = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m70\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgas\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgas\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trabalho/UFBA/New_project/libs/model.py:217\u001b[39m, in \u001b[36mMyModel.train_model\u001b[39m\u001b[34m(self, model, train_loader, val_loader, lr, epochs, optimizers, patience, factor, gas)\u001b[39m\n\u001b[32m    214\u001b[39m     x0_batch = y_pred_teacher[:, :\u001b[32m3\u001b[39m].detach().numpy()\n\u001b[32m    215\u001b[39m     z0_batch = y_true[:, \u001b[32m3\u001b[39m:].detach().numpy()\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     x_ss, z_ss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_steady_state_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu0_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mplenum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz0_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     z_ss = torch.tensor(z_ss, dtype=torch.float32)\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# Cálculo das perdas físicas\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trabalho/UFBA/New_project/libs/model.py:64\u001b[39m, in \u001b[36mMyModel.compute_steady_state_batch\u001b[39m\u001b[34m(self, u0_batch, plenum_sys, x0_batch, z0_batch, n_jobs)\u001b[39m\n\u001b[32m     61\u001b[39m args_list = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(u0_batch, x0_batch, z0_batch))\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Parallel(n_jobs=n_jobs) \u001b[38;5;28;01mas\u001b[39;00m parallel:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m x_ss_batch, z_ss_batch = \u001b[38;5;28mzip\u001b[39m(*results)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.stack(x_ss_batch), np.stack(z_ss_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_loss_values = model.train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr= 1e-3,\n",
    "    epochs=70,\n",
    "    optimizers=torch.optim.Adam,\n",
    "    patience=5,\n",
    "    factor=0.5,\n",
    "    gas = gas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAlphas_teste = 7\n",
    "\n",
    "sampler_N_RotS_teste = qmc.LatinHypercube(d=1)  # d=1 porque estamos amostrando uma única variável\n",
    "samples_N_RotS_teste = sampler_N_RotS_teste.random(n=nAlphas_teste+1)\n",
    "N_RotS_teste = qmc.scale(samples_N_RotS_teste, 600, 750).flatten()  # Redimensiona para 1D\n",
    "sampler_alphas_teste = qmc.LatinHypercube(d=1)\n",
    "samples_alphas_teste = sampler_alphas_teste.random(n=nAlphas_teste+1)\n",
    "alphas_teste = qmc.scale(samples_alphas_teste, 0.35, 0.65).flatten()  \n",
    "\n",
    "sim2 = sim = Simulation(plenum_sys, compressor, x0, z0, u0, nAlphas_teste, alphas_teste, N_RotS_teste, 40, dt, timestep)\n",
    "x_values_teste, z_values_teste, time_steps, alpha_values_teste, N_values_teste, x_teste, y_teste, x_min, x_max, y_min, y_max = sim.run()\n",
    "x_teste_np = x_teste.reshape(1,277, 3, 7)\n",
    "interval3 = np.linspace(0, 40*nAlphas_teste, len(x_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Rodar a inferência corretamente\n",
    "model.eval()  # Importante colocar a rede em modo de avaliação\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_teste)\n",
    "\n",
    "# Checar se y_pred realmente varia\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: mean={param.mean().item()}, std={param.std().item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    x_teste,\n",
    "    \"modelo_simples6.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=17,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\"},  # Permite batch variável\n",
    "        \"output\": {0: \"batch_size\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Converter o tensor para NumPy e ajustar o dtype\n",
    "x_teste_np = x_teste.detach().cpu().numpy().astype(np.float32)  # Garanta float32\n",
    "\n",
    "# Se o modelo esperar um batch dimension (ex: [batch, seq_len, features]), adicione:\n",
    "if x_teste_np.ndim == 1:\n",
    "    x_teste_np = x_teste_np[np.newaxis, ...]  # Adiciona dimensão de batch (batch=1)\n",
    "\n",
    "# Carregar o modelo ONNX\n",
    "ort_session = ort.InferenceSession(\"modelo_simples6.onnx\")\n",
    "\n",
    "# Executar inferência corretamente\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "outputs = ort_session.run(None, {input_name: x_teste_np})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Remover dimensões extras de y_pred e y_teste (se houver)\n",
    "outputs = outputs.squeeze()\n",
    "y_teste = y_teste.squeeze()\n",
    "\n",
    "# Número de variáveis de saída\n",
    "num_outputs = y_teste.shape[1]\n",
    "\n",
    "# Ajustar o tamanho da lista time_steps para corresponder aos dados de teste\n",
    "time_steps = time_steps[:y_teste.shape[0]]\n",
    " \n",
    "# Criar os gráficos separadamente para cada saída\n",
    "for i in range(num_outputs):\n",
    "    plt.figure(figsize=(8, 4))  # Criar uma nova figura para cada gráfico\n",
    "    plt.plot(time_steps, y_teste[:, i], label=\"Saída Esperada (y_teste)\", color=\"red\", linestyle=\"--\")\n",
    "    plt.plot(time_steps, outputs[:, i], label=\"Saída da Rede (outputs)\", color=\"blue\", linestyle=\"-\")\n",
    "    \n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.title(f\"Saída {i}\")  # Título do gráfico indicando o índice da saída\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()  # Mostrar o gráfico\n",
    "\n",
    "\"[0, 1, 2, 3, 5, 7, 9, 11]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"./modelo_simples6.onnx\"\n",
    "onnx_session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "massFlowrate_pred = [x_teste[0, 0, 0].item(), x_teste[0, 1, 0].item(), x_teste[0, 2, 0].item()]\n",
    "Temperatura = [x_teste[0, 0, 1].item(), x_teste[0, 1, 1].item(), x_teste[0, 2, 1].item()]\n",
    "PlenumPressure_pred = [x_teste[0, 0, 2].item(), x_teste[0, 1, 2].item(), x_teste[0, 2, 2].item()]\n",
    "Pressure2 = [x_teste[0, 0, 3].item(), x_teste[0, 1, 3].item(), x_teste[0, 2, 3].item()]\n",
    "Temperatura2 = [x_teste[0, 0, 4].item(), x_teste[0, 1, 4].item(), x_teste[0, 2, 4].item()]\n",
    "\n",
    "input_tensor = torch.zeros((1, 3, 7), dtype=torch.float32) \n",
    "\n",
    "tm1 = time.time()\n",
    "\n",
    "for i in range(len(interval3)):\n",
    "    # Atualizar os valores retroalimentados (massFlowrate e PlenumPressure)\n",
    "    input_tensor[0, :, 0] = torch.tensor(massFlowrate_pred[-3:])\n",
    "    input_tensor[0, :, 1] = torch.tensor(Temperatura[-3:])\n",
    "    input_tensor[0, :, 2] = torch.tensor(PlenumPressure_pred[-3:])\n",
    "    input_tensor[0, :, 3] = torch.tensor(Pressure2[-3:])\n",
    "    input_tensor[0, :, 4] = torch.tensor(Temperatura2[-3:])\n",
    "    input_tensor[0, :, 5] = x_teste[i, :, 5]\n",
    "    input_tensor[0, :, 6] = x_teste[i, :, 6]\n",
    "    # Copiar diretamente as variáveis restantes da entrada (colunas 2 a 6)\n",
    "\n",
    "    # Previsão com ONNX\n",
    "    onnx_inputs = {'input': input_tensor.numpy()}\n",
    "    onnx_outputs = onnx_session.run(None, onnx_inputs)\n",
    "\n",
    "    # Adicionar as novas previsões\n",
    "    massFlowrate_pred.append(onnx_outputs[0][0][0])\n",
    "    Temperatura.append(onnx_outputs[0][0][1])\n",
    "    PlenumPressure_pred.append(onnx_outputs[0][0][3])\n",
    "    Pressure2.append(onnx_outputs[0][0][4])\n",
    "    Temperatura2.append(onnx_outputs[0][0][11])\n",
    "tm2 = time.time()\n",
    "timeteste = tm2 - tm1\n",
    "\n",
    "print(f\"Tempo de teste: {timeteste:.4f}s\")\n",
    "Temperatura = np.array(Temperatura)\n",
    "lista = [massFlowrate_pred, Temperatura, PlenumPressure_pred, Pressure2, Temperatura2]\n",
    "lista = np.array(lista)\n",
    "print(lista.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Converter listas para numpy arrays\n",
    "massFlowrate_pred = np.array(massFlowrate_pred[3:])\n",
    "Temperatura_pred = np.array(Temperatura[3:])\n",
    "PlenumPressure_pred = np.array(PlenumPressure_pred[3:])\n",
    "Pressure2_pred = np.array(Pressure2[3:])\n",
    "Temperatura2_pred = np.array(Temperatura2[3:])\n",
    "\n",
    "# Garantir que y_teste está no formato de numpy array\n",
    "y_teste = np.array(y_teste)\n",
    "\n",
    "# Plotar os gráficos\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# 1. Mass Flowrate\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(massFlowrate_pred, label='Predito')\n",
    "plt.plot(y_teste[:, 0], label='Real', linestyle='--')\n",
    "plt.title('Mass Flowrate')\n",
    "plt.legend()\n",
    "\n",
    "# 2. Temperatura\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.plot(Temperatura_pred, label='Predito')\n",
    "plt.plot(y_teste[:, 1], label='Real', linestyle='--')\n",
    "plt.title('Temperatura')\n",
    "plt.legend()\n",
    "\n",
    "# 3. Plenum Pressure\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.plot(PlenumPressure_pred, label='Predito')\n",
    "plt.plot(y_teste[:, 3], label='Real', linestyle='--')  # Índice 4: conferir se bate com seu output\n",
    "plt.title('Plenum Pressure')\n",
    "plt.legend()\n",
    "\n",
    "# 4. Pressure 2\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.plot(Pressure2_pred, label='Predito')\n",
    "plt.plot(y_teste[:, 4], label='Real', linestyle='--')  # Índice 5: conferir\n",
    "plt.title('Pressure 2')\n",
    "plt.legend()\n",
    "\n",
    "# 5. Temperatura 2\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.plot(Temperatura2_pred, label='Predito')\n",
    "plt.plot(y_teste[:, 11], label='Real', linestyle='--')  # Índice 11: conferir\n",
    "plt.title('Temperatura 2')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
